{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JVengava/CS6910-DeepLearningAssignments/blob/main/Assignment3/Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgPFejViVSKQ",
        "outputId": "46c7ee0f-aaf8-4223-ddb8-225bd37b900e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.16-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 25.5 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |▌                               | 30 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█                               | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 92 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 419 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 430 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 440 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 450 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 460 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 471 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 481 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 491 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 501 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 512 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 522 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 532 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 542 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 552 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 563 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 573 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 583 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 593 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 604 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 614 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 624 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 634 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 645 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 655 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 665 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 675 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 686 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 696 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 706 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 716 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 727 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 737 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 747 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 757 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 768 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 778 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 788 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 798 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 808 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 819 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 829 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 839 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 849 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 860 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 870 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 880 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 890 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 901 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 911 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 921 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 931 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 942 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 952 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 962 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 972 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 983 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 993 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.0 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.1 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.5 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.6 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.6 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.6 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.6 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.6 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.6 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.6 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.6 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.7 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.7 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.7 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.7 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.7 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.7 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.7 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.7 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.8 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.8 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.8 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8 MB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.8 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.11-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 48.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=5672a63678222f6023d7162f1b563c0b96347b1f4e0fd96c5e0ee7a5c71b3891\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.11 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.16\n"
          ]
        }
      ],
      "source": [
        "pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aan5ZIPBWXwN",
        "outputId": "aa613baf-23b3-4415-a3b3-977c3d10c0e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-08 17:49:45--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 173.194.217.128, 74.125.31.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   234MB/s    in 7.8s    \n",
            "\n",
            "2022-05-08 17:49:53 (247 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf dakshina_dataset_v1.0.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "_5gDtFxKXIwR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import pathlib\n",
        "\n",
        "\n",
        "class DataProcessor():\n",
        "\n",
        "  def __init__(self, datapath, input_language = 'en', ouput_language = \"hi\"):\n",
        "  \n",
        "    self.input_language = input_language\n",
        "    self.ouput_language = ouput_language\n",
        "\n",
        "    self.trainpath = os.path.join(datapath, ouput_language, \"lexicons\", ouput_language+\".translit.sampled.train.tsv\")\n",
        "    self.valpath = os.path.join(datapath, ouput_language, \"lexicons\", ouput_language+\".translit.sampled.dev.tsv\")\n",
        "    self.testpath = os.path.join(datapath, ouput_language, \"lexicons\", ouput_language+\".translit.sampled.test.tsv\")\n",
        "\n",
        "    self.train = pd.read_csv(self.trainpath, sep=\"\\t\", names=[\"tgt\", \"src\", \"count\"])\n",
        "    self.val = pd.read_csv(self.valpath, sep=\"\\t\", names=[\"tgt\", \"src\", \"count\"])\n",
        "    self.test = pd.read_csv(self.testpath, sep=\"\\t\", names=[\"tgt\", \"src\", \"count\"])\n",
        "\n",
        "    # Train data\n",
        "    self.train_data = self.ProcessData(self.train[\"src\"].to_list(), self.train[\"tgt\"].to_list())\n",
        "    (self.input_words, self.output_words, self.input_chars, self.output_chars) = self.train_data\n",
        "\n",
        "    self.input_token_index_map = dict([(char, i) for i, char in enumerate(self.input_chars)])\n",
        "    self.output_token_index_map = dict([(char, i) for i, char in enumerate(self.output_chars)])\n",
        "\n",
        "    (self.train_encoder_input,self.train_decoder_input,self.train_decoder_target) = self.encode(self.input_words, self.output_words, self.input_chars, self.output_chars, self.input_token_index_map, self.output_token_index_map)\n",
        "    \n",
        "    # Validation data            \n",
        "    self.val_encoder_input, self.val_decoder_input, self.val_decoder_target = self.encode(self.val[\"src\"].to_list(), self.val[\"tgt\"].to_list(), list(self.input_token_index_map.keys()), list(self.output_token_index_map.keys()), self.input_token_index_map, self.output_token_index_map)        \n",
        "\n",
        "    # Test data    \n",
        "    self.test_encoder_input, self.test_decoder_input, self.test_decoder_target = self.encode(self.test[\"src\"].to_list(), self.test[\"tgt\"].to_list(), list(self.input_token_index_map.keys()), list(self.output_token_index_map.keys()), self.input_token_index_map, self.output_token_index_map)\n",
        "        \t\t    \n",
        "\n",
        "  def ProcessData(self, input , output):\n",
        "    input_words = []\n",
        "    output_words = []\n",
        "\n",
        "    input_chars = set()\n",
        "    output_chars = set()        \n",
        "    \n",
        "    input = [str(x) for x in input]\n",
        "    target = [str(x) for x in output]\n",
        "\n",
        "    for input_text, output_text in zip(input, output):\n",
        "        output_text = \"\\t\" + output_text + \"\\n\"\n",
        "        input_words.append(input_text)\n",
        "        output_words.append(output_text)          \n",
        "        for char in input_text:\n",
        "            if char not in input_chars:\n",
        "                input_chars.add(char)      \n",
        "        for char in output_text:\n",
        "            if char not in output_chars:\n",
        "                output_chars.add(char)\n",
        "\n",
        "    input_chars = sorted(list(input_chars))\n",
        "    output_chars = sorted(list(output_chars))\n",
        "\n",
        "    input_chars.append(\" \")\n",
        "    output_chars.append(\" \")\n",
        "\n",
        "    return input_words, output_words, input_chars, output_chars\n",
        "\n",
        "\n",
        "  def encode(self, input_words, output_words, input_chars, output_chars, input_token_index_map, output_token_index_map):\n",
        "        \n",
        "    print(\"Number of samples:\", len(input_words))\n",
        "    \n",
        "    num_encoder_tokens = len(input_chars)\n",
        "    num_decoder_tokens = len(output_chars)\t\t\n",
        "    print(\"Number of unique input tokens:\"\n",
        "    , num_encoder_tokens)\n",
        "    print(\"Number of unique output tokens:\"\n",
        "    , num_decoder_tokens)\n",
        "    \n",
        "    max_input_seq_length = max([len(txt) for txt in input_words])\n",
        "    max_output_seq_length = max([len(txt) for txt in output_words])\t\n",
        "    print(\"Max sequence length for inputs:\"\n",
        "    , max_input_seq_length)\n",
        "    print(\"Max sequence length for outputs:\"\n",
        "    , max_output_seq_length)\n",
        "        \n",
        "\n",
        "    encoder_input_data = np.zeros((len(input_words), max_input_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
        "    decoder_input_data = np.zeros((len(input_words), max_output_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "    decoder_target_data = np.zeros((len(input_words), max_output_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "    for i, (input_text, target_text) in enumerate(zip(input_words, output_words)):\n",
        "        for t, char in enumerate(input_text):\n",
        "            encoder_input_data[i, t, input_token_index_map[char]] = 1.0\n",
        "        encoder_input_data[i, t + 1 :, input_token_index_map[\" \"]] = 1.0\n",
        "        for t, char in enumerate(target_text):            \n",
        "            decoder_input_data[i, t, output_token_index_map[char]] = 1.0\n",
        "            if t > 0:                \n",
        "                decoder_target_data[i, t - 1, output_token_index_map[char]] = 1.0\n",
        "        decoder_input_data[i, t + 1 :, output_token_index_map[\" \"]] = 1.0\n",
        "        decoder_target_data[i, t:, output_token_index_map[\" \"]] = 1.0\n",
        "    \n",
        "    return encoder_input_data, decoder_input_data, decoder_target_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkRkk-Aokitb",
        "outputId": "d3e3c664-5f47-4b62-ce01-ed6c6e222841"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 44204\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 66\n",
            "Max sequence length for inputs: 20\n",
            "Max sequence length for outputs: 21\n",
            "Number of samples: 4358\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 66\n",
            "Max sequence length for inputs: 18\n",
            "Max sequence length for outputs: 14\n",
            "Number of samples: 4502\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 66\n",
            "Max sequence length for inputs: 16\n",
            "Max sequence length for outputs: 15\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "datapath = \"./dakshina_dataset_v1.0\"\n",
        "dataBase = DataProcessor(datapath) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "YCZ6oR4GkiuV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wandb\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model, Sequential,  Model\n",
        "from tensorflow.keras.layers import Dense, Input, InputLayer, Flatten, Activation, LSTM, SimpleRNN, GRU, TimeDistributed\n",
        "\n",
        "class SeqToSeqTranslation():\n",
        "\n",
        "  def __init__(self, modelConfigDict, input_token_index_map, output_token_index_map, using_pretrained_model = False):\n",
        "      self.latentDim = modelConfigDict[\"latentDim\"]\n",
        "      self.cell_type = modelConfigDict[\"cell_type\"]\n",
        "      self.numEncoders = modelConfigDict[\"numEncoders\"]\n",
        "      self.numDecoders = modelConfigDict[\"numDecoders\"]\n",
        "      self.hidden = modelConfigDict[\"hidden\"]\n",
        "      self.dropout = modelConfigDict[\"dropout\"]\n",
        "      self.input_token_index_map = input_token_index_map\n",
        "      self.output_token_index_map = output_token_index_map\n",
        "      \n",
        "\n",
        "  def build_model(self):       \n",
        "      if self.cell_type == \"RNN\":\n",
        "          # Encoder\n",
        "          encoder_inputs = Input(shape=(None, len(self.input_token_index_map)))\n",
        "          encoder_outputs = encoder_inputs\n",
        "          for i in range(1, self.numEncoders + 1):\n",
        "              encoder = SimpleRNN(self.latentDim, return_state=True, return_sequences=True, dropout=self.dropout)\n",
        "              encoder_outputs, state = encoder(encoder_inputs)\n",
        "          encoder_states = [state]\n",
        "\n",
        "          # Decoder\n",
        "          decoder_inputs = Input(shape=(None, len(self.output_token_index_map)))\n",
        "          decoder_outputs = decoder_inputs\n",
        "          for i in range(1, self.numDecoders + 1):\n",
        "              decoder = SimpleRNN(self.latentDim, return_sequences=True, return_state=True,dropout=self.dropout)\n",
        "              decoder_outputs, _ = decoder(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "          # dense\n",
        "          hidden = Dense(self.hidden, activation=\"relu\")\n",
        "          hidden_outputs = hidden(decoder_outputs)\n",
        "          decoder_dense = Dense(len(self.output_token_index_map), activation=\"softmax\")\n",
        "          decoder_outputs = decoder_dense(hidden_outputs)\n",
        "          model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "          \n",
        "          return model\n",
        "      \n",
        "      elif self.cell_type == \"LSTM\":\n",
        "          # encoder\n",
        "          encoder_inputs = Input(shape=(None, len(self.input_token_index_map)))\n",
        "          encoder_outputs = encoder_inputs\n",
        "          for i in range(1, self.numEncoders + 1):\n",
        "              encoder = LSTM(self.latentDim, return_state=True, return_sequences=True, dropout=self.dropout)\n",
        "              encoder_outputs, state_h, state_c = encoder(encoder_outputs)\n",
        "          encoder_states = [state_h, state_c]\n",
        "\n",
        "          # decoder\n",
        "          decoder_inputs = Input(shape=(None, len(self.output_token_index_map)))\n",
        "          decoder_outputs = decoder_inputs\n",
        "          for i in range(1, self.numDecoders + 1):\n",
        "              decoder = LSTM(self.latentDim, return_state=True, return_sequences=True, dropout=self.dropout)\n",
        "              decoder_outputs, _, _ = decoder(decoder_outputs, initial_state=encoder_states)\n",
        "\n",
        "          # dense\n",
        "          hidden = Dense(self.hidden, activation=\"relu\")\n",
        "          hidden_outputs = hidden(decoder_outputs)\n",
        "          decoder_dense = Dense(len(self.output_token_index_map), activation=\"softmax\")\n",
        "          decoder_outputs = decoder_dense(hidden_outputs)\n",
        "          model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "          \n",
        "          return model\n",
        "      \n",
        "      elif self.cell_type == \"GRU\":\n",
        "          # encoder\n",
        "          encoder_inputs = Input(shape=(None, len(self.input_token_index_map)))\n",
        "          encoder_outputs = encoder_inputs\n",
        "          for i in range(1, self.numEncoders + 1):\n",
        "              encoder = GRU(self.latentDim, return_state=True, return_sequences=True, dropout=self.dropout)\n",
        "              encoder_outputs, state = encoder(encoder_inputs)\n",
        "          encoder_states = [state]\n",
        "\n",
        "          # decoder\n",
        "          decoder_inputs = Input(shape=(None, len(self.output_token_index_map)))\n",
        "          decoder_outputs = decoder_inputs\n",
        "          for i in range(1, self.numDecoders + 1):\n",
        "              decoder = GRU(self.latentDim, return_sequences=True, return_state=True, dropout=self.dropout)\n",
        "              decoder_outputs, _ = decoder(decoder_inputs, initial_state=encoder_states)\n",
        "\n",
        "          # dense\n",
        "          hidden = Dense(self.hidden, activation=\"relu\")\n",
        "          hidden_outputs = hidden(decoder_outputs)\n",
        "          decoder_dense = Dense(len(self.output_token_index_map), activation=\"softmax\")\n",
        "          decoder_outputs = decoder_dense(hidden_outputs)\n",
        "          model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "          \n",
        "          return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02CdN_JTqbnw",
        "outputId": "2bfdc57d-b73a-4717-e83b-4b679560378d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lzaDKGjDnjMx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import RNN, LSTM, GRU, Dense\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "\n",
        "def train():    \n",
        "\n",
        "    config_defaults = {\n",
        "        \"cell_type\": \"GRU\",\n",
        "        \"latentDim\": 256,\n",
        "        \"hidden\": 128,\n",
        "        \"optimiser\": \"adam\",\n",
        "        \"numEncoders\": 3,\n",
        "        \"numDecoders\": 1,\n",
        "        \"dropout\": 0.1,\n",
        "        \"epochs\": 20,\n",
        "        \"batch_size\": 32,\n",
        "    }\n",
        "\n",
        "    \n",
        "    wandb.init(config=config_defaults,  project=\"CS6910_DeepLearning_Assignment3\", entity=\"cs21z032_cs22z005\")\n",
        "    config = wandb.config\n",
        "    \n",
        "    wandb.run.name = (str(config.cell_type)+ dataBase.input_language+ str(config.numEncoders)+ \"_\"+ dataBase.output_language+ \"_\"+ str(config.numDecoders)+ \"_\"+ config.optimiser+ \"_\"+ str(config.epochs)+ \"_\"+ str(config.dropout) + \"_\"+ str(config.batch_size)+ \"_\"+ str(config.latentDim))\n",
        "    wandb.run.save()\n",
        "\n",
        "    modelInit = SeqToSeqTranslation(config,input_token_index_map=dataBase.input_token_index_map, output_token_index_map=dataBase.output_token_index_map)\n",
        "    \n",
        "    model = modelInit.build_model()\n",
        "    \n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer=config.optimiser,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "    earlystopping = EarlyStopping(monitor=\"val_accuracy\", min_delta=0.01, patience=5, verbose=2, mode=\"auto\")\n",
        "\n",
        "    model.fit([dataBase.train_encoder_input, dataBase.train_decoder_input],dataBase.train_decoder_target,batch_size=config.batch_size,epochs=config.epochs,validation_data=([dataBase.val_encoder_input, dataBase.val_decoder_input], dataBase.val_decoder_target),callbacks=[earlystopping, WandbCallback()])\n",
        "\n",
        "    model.save(os.path.join(\"./TrainedModels\", wandb.run.name))\n",
        "    #model.save(os.path.join(\"/content/gdrive/MyDrive/CS6910_Assignment3/BestModelWithoutAttention\", wandb.run.name))\n",
        "    wandb.finish()  \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqxFribAqNrW"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "    \"name\": \"Bayesian Sweep\",\n",
        "    \"method\": \"bayes\",\n",
        "    \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
        "    \"parameters\": {\n",
        "        \n",
        "        \"batch_size\": {\"values\": [32, 64]},\n",
        "\n",
        "        \"cell_type\": {\"values\": [\"RNN\", \"GRU\", \"LSTM\"]},\n",
        "\n",
        "        \"optimiser\": {\"values\": [\"rmsprop\", \"adam\"]},\n",
        "\n",
        "        \"dropout\": {\"values\": [0.1, 0.2, 0.3]},\n",
        "\n",
        "        \"epochs\": {\"values\": [5,10,15, 20]},\n",
        "\n",
        "        \"hidden\": {\"values\": [128, 64]},\n",
        "\n",
        "        \"latentDim\": {\"values\": [256]},\n",
        "\n",
        "        \"numEncoders\": {\"values\": [1, 2, 3]},        \n",
        "\n",
        "        \"numDecoders\": {\"values\": [1, 2, 3]},  \n",
        "    },\n",
        "}\n",
        "\n",
        "# sweep_config = {\n",
        "#     \"name\": \"Bayesian Sweep without attention\",\n",
        "#     \"method\": \"bayes\",\n",
        "#     \"metric\": {\"name\": \"val_accuracy\", \"goal\": \"maximize\"},\n",
        "#     \"parameters\": {\n",
        "        \n",
        "#         \"cell_type\": {\"values\": [\"GRU\"]},\n",
        "        \n",
        "#         \"latentDim\": {\"values\": [256]},\n",
        "        \n",
        "#         \"hidden\": {\"values\": [128]},\n",
        "        \n",
        "#         \"optimiser\": {\"values\": [\"adam\"]},\n",
        "        \n",
        "#         \"numEncoders\": {\"values\": [3]},\n",
        "        \n",
        "#         \"numDecoders\": {\"values\": [1]},\n",
        "        \n",
        "#         \"dropout\": {\"values\": [0.1]},\n",
        "        \n",
        "#         \"epochs\": {\"values\": [20]},\n",
        "        \n",
        "#         \"batch_size\": {\"values\": [32]},\n",
        "#     },\n",
        "# }\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"CS6910_DeepLearning_Assignment3\", entity=\"cs21z032_cs22z005\")\n",
        "\n",
        "wandb.agent(sweep_id, train, count = 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QcPA0wDjrmBs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "232abb1537134d6897497395be213413",
            "feac50b0b0f54042b1119901e58210b4",
            "342fbbc0a97c4e678bcd28384cbd060f",
            "ea23753e97d04cd08772a82062f96ee6",
            "5cc611773dfe4da99634ec64325170fb",
            "cfa2f5ae96344613a68b921003fe90c0",
            "595c1d0f0b6b43918fc1bc21489285cc",
            "beb2aa0afd344d3db4cf8858e9bce5d0"
          ]
        },
        "outputId": "4e522ce8-9479-42b1-fea0-c367dfd7aa53"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220508_145744-2c6evs1x</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/cs21z032_cs22z005/CS6910_DeepLearning_Assignment3/runs/2c6evs1x\" target=\"_blank\">amber-snowball-88</a></strong> to <a href=\"https://wandb.ai/cs21z032_cs22z005/CS6910_DeepLearning_Assignment3\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished 0 examples\n",
            "Source: ank\n",
            "Original: अंक\n",
            "Predicted: एंक\n",
            "\n",
            "Accuracy: 0.0\n",
            "[5, 3, 17]\n",
            "[12, 3, 17]\n",
            "Finished 100 examples\n",
            "Source: anukulata\n",
            "Original: अनुकूलता\n",
            "Predicted: अनुकुलता\n",
            "\n",
            "Accuracy: 0.1782178217821782\n",
            "[5, 36, 54, 17, 55, 44, 32, 51]\n",
            "[5, 36, 54, 17, 54, 44, 32, 51]\n",
            "Finished 200 examples\n",
            "Source: avaru\n",
            "Original: अवरु\n",
            "Predicted: अवरू\n",
            "\n",
            "Accuracy: 0.19900497512437812\n",
            "[5, 45, 43, 54]\n",
            "[5, 45, 43, 55]\n",
            "Finished 300 examples\n",
            "Source: aabru\n",
            "Original: आबरू\n",
            "Predicted: अब्रू\n",
            "\n",
            "Accuracy: 0.2691029900332226\n",
            "[6, 39, 43, 55]\n",
            "[5, 39, 63, 43, 55]\n",
            "Finished 400 examples\n",
            "Source: inhaletion\n",
            "Original: इनहेलेशन\n",
            "Predicted: इंहालियों\n",
            "\n",
            "Accuracy: 0.27680798004987534\n",
            "[7, 36, 49, 58, 44, 58, 46, 36]\n",
            "[7, 3, 49, 51, 44, 52, 42, 61, 3]\n",
            "Finished 500 examples\n",
            "Source: umesh\n",
            "Original: उमेश\n",
            "Predicted: उमेश\n",
            "\n",
            "Accuracy: 0.27944111776447106\n",
            "[9, 41, 58, 46]\n",
            "[9, 41, 58, 46]\n",
            "Finished 600 examples\n",
            "Source: asphalt\n",
            "Original: एस्फाल्ट\n",
            "Predicted: अस्पालत\n",
            "\n",
            "Accuracy: 0.2795341098169717\n",
            "[12, 48, 63, 38, 51, 44, 63, 27]\n",
            "[5, 48, 63, 37, 51, 44, 32]\n",
            "Finished 700 examples\n",
            "Source: kaping\n",
            "Original: कपिंग\n",
            "Predicted: कपींग\n",
            "\n",
            "Accuracy: 0.2738944365192582\n",
            "[17, 37, 52, 3, 19]\n",
            "[17, 37, 53, 3, 19]\n",
            "Finished 800 examples\n",
            "Source: kasim\n",
            "Original: कासिम\n",
            "Predicted: कसीम\n",
            "\n",
            "Accuracy: 0.28963795255930086\n",
            "[17, 51, 48, 52, 41]\n",
            "[17, 48, 53, 41]\n",
            "Finished 900 examples\n",
            "Source: kshitij\n",
            "Original: क्षितिज\n",
            "Predicted: क्षितिज\n",
            "\n",
            "Accuracy: 0.28412874583795783\n",
            "[17, 63, 47, 52, 32, 52, 24]\n",
            "[17, 63, 47, 52, 32, 52, 24]\n",
            "Finished 1000 examples\n",
            "Source: girjagharon\n",
            "Original: गिरजाघरों\n",
            "Predicted: गीर्घारारों\n",
            "\n",
            "Accuracy: 0.28471528471528473\n",
            "[19, 52, 43, 24, 51, 20, 43, 61, 3]\n",
            "[19, 53, 43, 63, 20, 51, 43, 51, 43, 61, 3]\n",
            "Finished 1100 examples\n",
            "Source: chatushkoniy\n",
            "Original: चतुष्कोणीय\n",
            "Predicted: चतुष्क्योलय\n",
            "\n",
            "Accuracy: 0.28701180744777477\n",
            "[22, 32, 54, 47, 63, 17, 61, 31, 53, 42]\n",
            "[22, 32, 54, 47, 63, 17, 63, 42, 61, 44, 42]\n",
            "Finished 1200 examples\n",
            "Source: chhagla\n",
            "Original: छागला\n",
            "Predicted: छागला\n",
            "\n",
            "Accuracy: 0.2939217318900916\n",
            "[23, 51, 19, 44, 51]\n",
            "[23, 51, 19, 44, 51]\n",
            "Finished 1300 examples\n",
            "Source: jalagati\n",
            "Original: जलगति\n",
            "Predicted: जलगाती\n",
            "\n",
            "Accuracy: 0.2920830130668716\n",
            "[24, 44, 19, 32, 52]\n",
            "[24, 44, 19, 51, 32, 53]\n",
            "Finished 1400 examples\n",
            "Source: jue\n",
            "Original: जुए\n",
            "Predicted: जू\n",
            "\n",
            "Accuracy: 0.2940756602426838\n",
            "[24, 54, 12]\n",
            "[24, 55]\n",
            "Finished 1500 examples\n",
            "Source: tau\n",
            "Original: टाऊ\n",
            "Predicted: टाऊ\n",
            "\n",
            "Accuracy: 0.3077948034643571\n",
            "[27, 51, 10]\n",
            "[27, 51, 10]\n",
            "Finished 1600 examples\n",
            "Source: dulne\n",
            "Original: डुलने\n",
            "Predicted: डूलने\n",
            "\n",
            "Accuracy: 0.3029356652092442\n",
            "[29, 54, 44, 36, 58]\n",
            "[29, 55, 44, 36, 58]\n",
            "Finished 1700 examples\n",
            "Source: tapmano\n",
            "Original: तापमानों\n",
            "Predicted: तप्माणों\n",
            "\n",
            "Accuracy: 0.29570840681951793\n",
            "[32, 51, 37, 41, 51, 36, 61, 3]\n",
            "[32, 37, 63, 41, 51, 31, 61, 3]\n",
            "Finished 1800 examples\n",
            "Source: dahal\n",
            "Original: दहल\n",
            "Predicted: डाहल\n",
            "\n",
            "Accuracy: 0.2876179900055525\n",
            "[34, 49, 44]\n",
            "[29, 51, 49, 44]\n",
            "Finished 1900 examples\n",
            "Source: devapur\n",
            "Original: देवापुर\n",
            "Predicted: डेवापुर\n",
            "\n",
            "Accuracy: 0.2824829037348764\n",
            "[34, 58, 45, 51, 37, 54, 43]\n",
            "[29, 58, 45, 51, 37, 54, 43]\n",
            "Finished 2000 examples\n",
            "Source: najariyon\n",
            "Original: नजरियों\n",
            "Predicted: नज़रियों\n",
            "\n",
            "Accuracy: 0.2898550724637681\n",
            "[36, 24, 43, 52, 42, 61, 3]\n",
            "[36, 24, 50, 43, 52, 42, 61, 3]\n",
            "Finished 2100 examples\n",
            "Source: nipatara\n",
            "Original: निपटारा\n",
            "Predicted: निपटारा\n",
            "\n",
            "Accuracy: 0.29224178962398856\n",
            "[36, 52, 37, 27, 51, 43, 51]\n",
            "[36, 52, 37, 27, 51, 43, 51]\n",
            "Finished 2200 examples\n",
            "Source: patkathaein\n",
            "Original: पटकथाएं\n",
            "Predicted: पत्काराएं\n",
            "\n",
            "Accuracy: 0.3016810540663335\n",
            "[37, 27, 17, 33, 51, 12, 3]\n",
            "[37, 32, 63, 17, 51, 43, 51, 12, 3]\n",
            "Finished 2300 examples\n",
            "Source: paathshaalaayein\n",
            "Original: पाठशालाएं\n",
            "Predicted: थंखलाएं\n",
            "\n",
            "Accuracy: 0.3055193394176445\n",
            "[37, 51, 28, 46, 51, 44, 51, 12, 3]\n",
            "[33, 3, 18, 44, 51, 12, 3]\n",
            "Finished 2400 examples\n",
            "Source: pushpa\n",
            "Original: पुष्पा\n",
            "Predicted: पुष्प\n",
            "\n",
            "Accuracy: 0.3027905039566847\n",
            "[37, 54, 47, 63, 37, 51]\n",
            "[37, 54, 47, 63, 37]\n",
            "Finished 2500 examples\n",
            "Source: prathmikta\n",
            "Original: प्राथमिकता\n",
            "Predicted: प्राथमिकता\n",
            "\n",
            "Accuracy: 0.30307876849260296\n",
            "[37, 63, 43, 51, 33, 41, 52, 17, 32, 51]\n",
            "[37, 63, 43, 51, 33, 41, 52, 17, 32, 51]\n",
            "Finished 2600 examples\n",
            "Source: firti\n",
            "Original: फिरती\n",
            "Predicted: फर्ती\n",
            "\n",
            "Accuracy: 0.29988465974625145\n",
            "[38, 52, 43, 32, 53]\n",
            "[38, 43, 63, 32, 53]\n",
            "Finished 2700 examples\n",
            "Source: batlaye\n",
            "Original: बतलाए\n",
            "Predicted: बतलाए\n",
            "\n",
            "Accuracy: 0.2987782302850796\n",
            "[39, 32, 44, 51, 12]\n",
            "[39, 32, 44, 51, 12]\n",
            "Finished 2800 examples\n",
            "Source: baalti\n",
            "Original: बाल्टी\n",
            "Predicted: बालती\n",
            "\n",
            "Accuracy: 0.3048911103177437\n",
            "[39, 51, 44, 63, 27, 53]\n",
            "[39, 51, 44, 32, 53]\n",
            "Finished 2900 examples\n",
            "Source: bodra\n",
            "Original: बोदरा\n",
            "Predicted: बोदरा\n",
            "\n",
            "Accuracy: 0.307480179248535\n",
            "[39, 61, 34, 43, 51]\n",
            "[39, 61, 34, 43, 51]\n",
            "Finished 3000 examples\n",
            "Source: bhulo\n",
            "Original: भूलो\n",
            "Predicted: भूलो\n",
            "\n",
            "Accuracy: 0.311562812395868\n",
            "[40, 55, 44, 61]\n",
            "[40, 55, 44, 61]\n",
            "Finished 3100 examples\n",
            "Source: mahkane\n",
            "Original: महकने\n",
            "Predicted: महकाने\n",
            "\n",
            "Accuracy: 0.3124798452112222\n",
            "[41, 49, 17, 36, 58]\n",
            "[41, 49, 17, 51, 36, 58]\n",
            "Finished 3200 examples\n",
            "Source: mubarkpur\n",
            "Original: मुबारकपुर\n",
            "Predicted: मुबारकपूर\n",
            "\n",
            "Accuracy: 0.3133395813808185\n",
            "[41, 54, 39, 51, 43, 17, 37, 54, 43]\n",
            "[41, 54, 39, 51, 43, 17, 37, 55, 43]\n",
            "Finished 3300 examples\n",
            "Source: mohani\n",
            "Original: मोहानी\n",
            "Predicted: मोहनी\n",
            "\n",
            "Accuracy: 0.3153589821266283\n",
            "[41, 61, 49, 51, 36, 53]\n",
            "[41, 61, 49, 36, 53]\n",
            "Finished 3400 examples\n",
            "Source: rajman\n",
            "Original: राजमां\n",
            "Predicted: राजमान\n",
            "\n",
            "Accuracy: 0.31696559835342547\n",
            "[43, 51, 24, 41, 51, 3]\n",
            "[43, 51, 24, 41, 51, 36]\n",
            "Finished 3500 examples\n",
            "Source: reshey\n",
            "Original: रेशे\n",
            "Predicted: रेशे\n",
            "\n",
            "Accuracy: 0.3184804341616681\n",
            "[43, 58, 46, 58]\n",
            "[43, 58, 46, 58]\n",
            "Finished 3600 examples\n",
            "Source: lanchar\n",
            "Original: लांचर\n",
            "Predicted: लांचर\n",
            "\n",
            "Accuracy: 0.3182449319633435\n",
            "[44, 51, 3, 22, 43]\n",
            "[44, 51, 3, 22, 43]\n",
            "Finished 3700 examples\n",
            "Source: varnit\n",
            "Original: वर्णित\n",
            "Predicted: वर्णीत\n",
            "\n",
            "Accuracy: 0.31667116995406647\n",
            "[45, 43, 63, 31, 52, 32]\n",
            "[45, 43, 63, 31, 53, 32]\n",
            "Finished 3800 examples\n",
            "Source: vimarshon\n",
            "Original: विमर्शों\n",
            "Predicted: विमार्शन\n",
            "\n",
            "Accuracy: 0.31912654564588266\n",
            "[45, 52, 41, 43, 63, 46, 61, 3]\n",
            "[45, 52, 41, 51, 43, 63, 46, 36]\n",
            "Finished 3900 examples\n",
            "Source: shamitabh\n",
            "Original: शमिताभ\n",
            "Predicted: शमीता\n",
            "\n",
            "Accuracy: 0.317098179953858\n",
            "[46, 41, 52, 32, 51, 40]\n",
            "[46, 41, 53, 32, 51]\n",
            "Finished 4000 examples\n",
            "Source: samprbhuta\n",
            "Original: संप्रभुता\n",
            "Predicted: संप्रभूति\n",
            "\n",
            "Accuracy: 0.3181704573856536\n",
            "[48, 3, 37, 63, 43, 40, 54, 32, 51]\n",
            "[48, 3, 37, 63, 43, 40, 55, 32, 52]\n",
            "Finished 4100 examples\n",
            "Source: sargana\n",
            "Original: सरगना\n",
            "Predicted: सर्गना\n",
            "\n",
            "Accuracy: 0.31870275542550597\n",
            "[48, 43, 19, 36, 51]\n",
            "[48, 43, 63, 19, 36, 51]\n",
            "Finished 4200 examples\n",
            "Source: simate\n",
            "Original: सिमटे\n",
            "Predicted: सिमाते\n",
            "\n",
            "Accuracy: 0.317305403475363\n",
            "[48, 52, 41, 27, 58]\n",
            "[48, 52, 41, 51, 32, 58]\n",
            "Finished 4300 examples\n",
            "Source: self\n",
            "Original: सेल्फ\n",
            "Predicted: सेल्फ\n",
            "\n",
            "Accuracy: 0.31853057428505\n",
            "[48, 58, 44, 63, 38]\n",
            "[48, 58, 44, 63, 38]\n",
            "Finished 4400 examples\n",
            "Source: sweet\n",
            "Original: स्वीट\n",
            "Predicted: स्वीत\n",
            "\n",
            "Accuracy: 0.31879118382185867\n",
            "[48, 63, 45, 53, 27]\n",
            "[48, 63, 45, 53, 32]\n",
            "Finished 4500 examples\n",
            "Source: hostes\n",
            "Original: होस्टेस\n",
            "Predicted: होस्टेस\n",
            "\n",
            "Accuracy: 0.3192623861364141\n",
            "[49, 61, 48, 63, 27, 58, 48]\n",
            "[49, 61, 48, 63, 27, 58, 48]\n",
            "Test Accuracy: 1438\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "232abb1537134d6897497395be213413"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_accuracy</td><td>0.31941</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">amber-snowball-88</strong>: <a href=\"https://wandb.ai/cs21z032_cs22z005/CS6910_DeepLearning_Assignment3/runs/2c6evs1x\" target=\"_blank\">https://wandb.ai/cs21z032_cs22z005/CS6910_DeepLearning_Assignment3/runs/2c6evs1x</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220508_145744-2c6evs1x/logs</code>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Dense, Input, InputLayer, Flatten, Activation, LSTM, SimpleRNN, GRU, TimeDistributed, Concatenate\n",
        "\n",
        "\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "model = load_model(\"/content/gdrive/MyDrive/CS6910_Assignment3/BestModelWithoutAttention/GRUen3_hi_1_adam_20_0.1_32_256\")\n",
        "\n",
        "config_best = {\"cell_type\": \"GRU\", \"latentDim\": 256,\" hidden\": 128, \"optimiser\": \"adam\", \"numEncoders\": 3, \"numDecoders\": 1, \"dropout\": 0.1, \"epochs\": 20, \"batch_size\": 32}\n",
        "\n",
        "\n",
        "def test_model(model):    \n",
        "    wandb.init(config=config_best,  project=\"CS6910_DeepLearning_Assignment3\", entity=\"cs21z032_cs22z005\")\n",
        "    config = wandb.config\n",
        "    wandb.run.name = (\"Inference_\" + str(config.cell_type)+ dataBase.source_lang+ str(config.numEncoders)+ \"_\"+ dataBase.target_lang+ \"_\"+ str(config.numDecoders)+ \"_\"+ config.optimiser+ \"_\"+ str(config.epochs)+ \"_\"+ str(config.dropout) + \"_\"+ str(config.batch_size)+ \"_\"+ str(config.latentDim))\n",
        "    wandb.run.save()\n",
        "\n",
        "\n",
        "    if config.cell_type == \"LSTM\":\n",
        "        # encoder\n",
        "        encoder_inputs = model.input[0]\n",
        "        \n",
        "        if config.numEncoders == 1:\n",
        "            encoder_outputs, state_h_enc, state_c_enc = model.get_layer(name = \"lstm\").output \n",
        "        else:           \n",
        "            encoder_outputs, state_h_enc, state_c_enc = model.get_layer(name = \"lstm_\"+ str(config.numEncoders-1)).output\n",
        "\n",
        "        encoder_states = [state_h_enc, state_c_enc]\n",
        "        encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "        # decoder\n",
        "        decoder_inputs = model.input[1]        \n",
        "        decoder_state_input_c = Input(shape=(config.latentDim,), name=\"input_4\")\n",
        "        decoder_state_input_h = Input(shape=(config.latentDim,), name=\"input_3\")\n",
        "        decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "        \n",
        "        decoder_lstm = model.layers[-3]\n",
        "        decoder_outputs, state_h_dec, state_c_dec = decoder_lstm( decoder_inputs, initial_state=decoder_states_inputs )\n",
        "        decoder_states = [state_h_dec, state_c_dec]\n",
        "\n",
        "        decoder_dense = model.layers[-2]\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "        \n",
        "        decoder_dense = model.layers[-1]\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "    elif config.cell_type == \"GRU\" or config.cell_type == \"RNN\":\n",
        "        # encoder\n",
        "        encoder_inputs = model.input[0]\n",
        "        if config.cell_type == \"GRU\":\n",
        "            if config.numEncoders == 1:\n",
        "                encoder_outputs, state = model.get_layer(name = \"gru\").output\n",
        "            else:\n",
        "                encoder_outputs, state = model.get_layer(name = \"gru_\"+ str(config.numEncoders-1)).output\n",
        "        else:\n",
        "            if config.numEncoders == 1:\n",
        "                encoder_outputs, state = model.get_layer(name = \"simple_rnn\").output\n",
        "            else:\n",
        "                encoder_outputs, state = model.get_layer(name = \"simple_rnn_\"+ str(config.numEncoders-1)).output\n",
        "\n",
        "        encoder_states = [state]\n",
        "        encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "        # decoder\n",
        "        decoder_inputs = model.input[1]\n",
        "        decoder_state = Input(shape=(config.latentDim,), name=\"input_3\")\n",
        "        decoder_states_inputs = [decoder_state]\n",
        "        decoder_gru = model.layers[-3]\n",
        "        (decoder_outputs, state,) = decoder_gru(decoder_inputs, initial_state=decoder_states_inputs)\n",
        "        decoder_states = [state]\n",
        "        decoder_dense = model.layers[-2]\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "        decoder_dense = model.layers[-1]\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "        decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "    def decode_sequence(input_seq):\n",
        "      states_value = encoder_model.predict(input_seq)\n",
        "      output_sequence = np.zeros((1, 1, len(dataBase.output_token_index_map)))\n",
        "      output_sequence[0, 0, dataBase.output_token_index_map[\"\\n\"]] = 1.0\n",
        "\n",
        "      stop_condition = False\n",
        "      decoded_sentence = \"\"\n",
        "      output_index_token_map = dict((i, char) for char, i in dataBase.output_token_index_map.items())\n",
        "      while not stop_condition:\n",
        "          if config.cell_type == \"LSTM\":\n",
        "              output_tokens, h, c = decoder_model.predict([output_sequence] + states_value)\n",
        "          elif config.cell_type == \"RNN\" or config.cell_type == \"GRU\":\n",
        "              states_value = states_value[0].reshape((1, 256))\n",
        "              output_tokens, h = decoder_model.predict([output_sequence] + [states_value])\n",
        "                    \n",
        "          sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "          sampled_char = output_index_token_map[sampled_token_index]\n",
        "          decoded_sentence += sampled_char\n",
        "          \n",
        "          if sampled_char == \"\\n\" or len(decoded_sentence) > 25:\n",
        "              stop_condition = True\n",
        "\n",
        "          output_sequence = np.zeros((1, 1, len(dataBase.output_token_index_map)))\n",
        "          output_sequence[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "          if config.cell_type == \"LSTM\":\n",
        "              states_value = [h, c]\n",
        "          elif config.cell_type == \"RNN\" or config.cell_type == \"GRU\":\n",
        "              states_value = [h]\n",
        "      return decoded_sentence\n",
        "\n",
        "    acc = 0\n",
        "    input_text = []\n",
        "    original = []\n",
        "    predictions = []\n",
        "    \n",
        "    for i, row in dataBase.test.iterrows():\n",
        "        input_seq = dataBase.test_encoder_input[i : i + 1]\n",
        "        decoded_sentence = decode_sequence(input_seq)\n",
        "        predictions.append(decoded_sentence)\n",
        "    \n",
        "        original_tokens = [dataBase.output_token_index_map[x] for x in row[\"tgt\"]]\n",
        "        predicted_tokens = [dataBase.output_token_index_map[x] for x in decoded_sentence.rstrip(\"\\n\")]\n",
        "            \n",
        "        input_text.append(row['src'])\n",
        "        original.append(row['tgt'])\n",
        "        \n",
        "        if original_tokens == predicted_tokens:\n",
        "            acc += 1\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Finished {i} examples\")\n",
        "            print(f\"Input text: {row['src']}\")\n",
        "            print(f\"Original: {row['tgt']}\")\n",
        "            print(f\"Predicted: {decoded_sentence}\")\n",
        "            print(f\"Accuracy: {acc / (i+1)}\")\n",
        "            print(original_tokens)\n",
        "            print(predicted_tokens)\n",
        "            \n",
        "\n",
        "    print(f'Test Accuracy: {acc}')\n",
        "    wandb.log({'test_accuracy': acc / len(dataBase.test)})\n",
        "    wandb.finish()\n",
        "    return acc / len(dataBase.test), input_text, original, predictions\n",
        "\n",
        "\n",
        "acc,input_text, original, predictions = test_model(model)\n",
        "data = [{\"input\":input_text[i], \"true\": original[i], \"predicted\": predictions[i]} for i in range(len(input_text))] \n",
        "test_predictions = pd.DataFrame(data)\n",
        "test_predictions.to_csv('/content/gdrive/MyDrive/CS6910_Assignment3/BestModelWithoutAttention/predictions_vanilla.csv', index=False, sep='\\t')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Assignment 3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "232abb1537134d6897497395be213413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_feac50b0b0f54042b1119901e58210b4",
              "IPY_MODEL_342fbbc0a97c4e678bcd28384cbd060f"
            ],
            "layout": "IPY_MODEL_ea23753e97d04cd08772a82062f96ee6"
          }
        },
        "feac50b0b0f54042b1119901e58210b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cc611773dfe4da99634ec64325170fb",
            "placeholder": "​",
            "style": "IPY_MODEL_cfa2f5ae96344613a68b921003fe90c0",
            "value": "0.016 MB of 0.016 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "342fbbc0a97c4e678bcd28384cbd060f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_595c1d0f0b6b43918fc1bc21489285cc",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_beb2aa0afd344d3db4cf8858e9bce5d0",
            "value": 1
          }
        },
        "ea23753e97d04cd08772a82062f96ee6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cc611773dfe4da99634ec64325170fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa2f5ae96344613a68b921003fe90c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "595c1d0f0b6b43918fc1bc21489285cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb2aa0afd344d3db4cf8858e9bce5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}